{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ISHITA MANGAL - E19CSE083\n",
        "FLOWER RECOGNITION SYSTEM"
      ],
      "metadata": {
        "id": "8REIGyF2m_-x"
      },
      "id": "8REIGyF2m_-x"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25312c1d",
      "metadata": {
        "id": "25312c1d"
      },
      "outputs": [],
      "source": [
        "#importing_libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0194fa59",
      "metadata": {
        "id": "0194fa59"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "# from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4edd9c2f",
      "metadata": {
        "id": "4edd9c2f"
      },
      "outputs": [],
      "source": [
        "#Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01f28d83",
      "metadata": {
        "id": "01f28d83"
      },
      "outputs": [],
      "source": [
        "#Training image processing "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19132ab9",
      "metadata": {
        "id": "19132ab9",
        "outputId": "74e6e476-4270-47e5-f26b-8a1c31056ebb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2877 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "        'training_set',\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e44aa2bf",
      "metadata": {
        "id": "e44aa2bf"
      },
      "outputs": [],
      "source": [
        "#Test image processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c69f7426",
      "metadata": {
        "id": "c69f7426",
        "outputId": "075c9f36-774e-48e6-e6f6-4b3e067c079c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1440 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "        'test_set',\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4d71788",
      "metadata": {
        "id": "c4d71788"
      },
      "outputs": [],
      "source": [
        "#Buidling Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19f4fb95",
      "metadata": {
        "id": "19f4fb95"
      },
      "outputs": [],
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33d33523",
      "metadata": {
        "id": "33d33523"
      },
      "outputs": [],
      "source": [
        "#Building Convolution layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18e03f83",
      "metadata": {
        "id": "18e03f83"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=64 , kernel_size=3 , activation='relu' , input_shape=[64,64,3]))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eccdd4f7",
      "metadata": {
        "id": "eccdd4f7"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=64 , kernel_size=3 , activation='relu' ))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2 , strides=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f0e684a",
      "metadata": {
        "id": "7f0e684a"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dropout(0.9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbc0036d",
      "metadata": {
        "id": "dbc0036d"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d0643d1",
      "metadata": {
        "id": "9d0643d1"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42f4d429",
      "metadata": {
        "id": "42f4d429"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=5 , activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63224265",
      "metadata": {
        "id": "63224265"
      },
      "outputs": [],
      "source": [
        "cnn.compile(optimizer = 'rmsprop' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5adfa92",
      "metadata": {
        "id": "d5adfa92",
        "outputId": "f759a62a-f8b2-48b9-b85c-ee1cdcfd19d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "90/90 [==============================] - 23s 249ms/step - loss: 1.5491 - accuracy: 0.2882 - val_loss: 1.2453 - val_accuracy: 0.4771\n",
            "Epoch 2/30\n",
            "90/90 [==============================] - 20s 227ms/step - loss: 1.2371 - accuracy: 0.4797 - val_loss: 1.0699 - val_accuracy: 0.5813\n",
            "Epoch 3/30\n",
            "90/90 [==============================] - 21s 228ms/step - loss: 1.1504 - accuracy: 0.5178 - val_loss: 1.0794 - val_accuracy: 0.5854\n",
            "Epoch 4/30\n",
            "90/90 [==============================] - 21s 230ms/step - loss: 1.1189 - accuracy: 0.5459 - val_loss: 1.0984 - val_accuracy: 0.5778\n",
            "Epoch 5/30\n",
            "90/90 [==============================] - 21s 233ms/step - loss: 1.0757 - accuracy: 0.5955 - val_loss: 0.9469 - val_accuracy: 0.6486\n",
            "Epoch 6/30\n",
            "90/90 [==============================] - 21s 233ms/step - loss: 0.9950 - accuracy: 0.6110 - val_loss: 1.0588 - val_accuracy: 0.6104\n",
            "Epoch 7/30\n",
            "90/90 [==============================] - 21s 231ms/step - loss: 1.0098 - accuracy: 0.6034 - val_loss: 1.6286 - val_accuracy: 0.4396\n",
            "Epoch 8/30\n",
            "90/90 [==============================] - 21s 235ms/step - loss: 0.9923 - accuracy: 0.5988 - val_loss: 0.9099 - val_accuracy: 0.6639\n",
            "Epoch 9/30\n",
            "90/90 [==============================] - 22s 240ms/step - loss: 0.9772 - accuracy: 0.6336 - val_loss: 0.8853 - val_accuracy: 0.6625\n",
            "Epoch 10/30\n",
            "90/90 [==============================] - 21s 232ms/step - loss: 0.9425 - accuracy: 0.6355 - val_loss: 0.8727 - val_accuracy: 0.6764\n",
            "Epoch 11/30\n",
            "90/90 [==============================] - 21s 229ms/step - loss: 0.9257 - accuracy: 0.6436 - val_loss: 0.8999 - val_accuracy: 0.6646\n",
            "Epoch 12/30\n",
            "90/90 [==============================] - 21s 230ms/step - loss: 0.9179 - accuracy: 0.6455 - val_loss: 0.8865 - val_accuracy: 0.6757\n",
            "Epoch 13/30\n",
            "90/90 [==============================] - 21s 229ms/step - loss: 0.9038 - accuracy: 0.6583 - val_loss: 0.8285 - val_accuracy: 0.6854\n",
            "Epoch 14/30\n",
            "90/90 [==============================] - 21s 229ms/step - loss: 0.8877 - accuracy: 0.6392 - val_loss: 0.7767 - val_accuracy: 0.7118\n",
            "Epoch 15/30\n",
            "90/90 [==============================] - 21s 228ms/step - loss: 0.8580 - accuracy: 0.6803 - val_loss: 0.9607 - val_accuracy: 0.6556\n",
            "Epoch 16/30\n",
            "90/90 [==============================] - 20s 227ms/step - loss: 0.8627 - accuracy: 0.6665 - val_loss: 1.0180 - val_accuracy: 0.6083\n",
            "Epoch 17/30\n",
            "90/90 [==============================] - 21s 228ms/step - loss: 0.8797 - accuracy: 0.6551 - val_loss: 0.7979 - val_accuracy: 0.7014\n",
            "Epoch 18/30\n",
            "90/90 [==============================] - 21s 228ms/step - loss: 0.8358 - accuracy: 0.6844 - val_loss: 0.7753 - val_accuracy: 0.7021\n",
            "Epoch 19/30\n",
            "90/90 [==============================] - 20s 228ms/step - loss: 0.8582 - accuracy: 0.6672 - val_loss: 0.8452 - val_accuracy: 0.7069\n",
            "Epoch 20/30\n",
            "90/90 [==============================] - 21s 229ms/step - loss: 0.8119 - accuracy: 0.6815 - val_loss: 0.8676 - val_accuracy: 0.6806\n",
            "Epoch 21/30\n",
            "90/90 [==============================] - 20s 227ms/step - loss: 0.8532 - accuracy: 0.6671 - val_loss: 0.9068 - val_accuracy: 0.6722\n",
            "Epoch 22/30\n",
            "90/90 [==============================] - 20s 226ms/step - loss: 0.8598 - accuracy: 0.6731 - val_loss: 1.1943 - val_accuracy: 0.6042\n",
            "Epoch 23/30\n",
            "90/90 [==============================] - 20s 226ms/step - loss: 0.8239 - accuracy: 0.6775 - val_loss: 0.8000 - val_accuracy: 0.7083\n",
            "Epoch 24/30\n",
            "90/90 [==============================] - 20s 227ms/step - loss: 0.8199 - accuracy: 0.6791 - val_loss: 1.0022 - val_accuracy: 0.6424\n",
            "Epoch 25/30\n",
            "90/90 [==============================] - 21s 228ms/step - loss: 0.8062 - accuracy: 0.6914 - val_loss: 0.8449 - val_accuracy: 0.7000\n",
            "Epoch 26/30\n",
            "90/90 [==============================] - 20s 228ms/step - loss: 0.8285 - accuracy: 0.6942 - val_loss: 0.8717 - val_accuracy: 0.6958\n",
            "Epoch 27/30\n",
            "90/90 [==============================] - 20s 227ms/step - loss: 0.8142 - accuracy: 0.6927 - val_loss: 0.7663 - val_accuracy: 0.7090\n",
            "Epoch 28/30\n",
            "90/90 [==============================] - 20s 227ms/step - loss: 0.7923 - accuracy: 0.7071 - val_loss: 0.8175 - val_accuracy: 0.7132\n",
            "Epoch 29/30\n",
            "90/90 [==============================] - 20s 228ms/step - loss: 0.8089 - accuracy: 0.6952 - val_loss: 0.9164 - val_accuracy: 0.6986\n",
            "Epoch 30/30\n",
            "90/90 [==============================] - 21s 230ms/step - loss: 0.8039 - accuracy: 0.7035 - val_loss: 0.7968 - val_accuracy: 0.7208\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x240a19bda90>"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cnn.fit(x = training_set , validation_data = test_set , epochs = 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdf9a399",
      "metadata": {
        "id": "bdf9a399"
      },
      "outputs": [],
      "source": [
        "#Preprocess New image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc20dfda",
      "metadata": {
        "id": "cc20dfda",
        "outputId": "1983aac3-a0f0-4750-9b15-291296e6221d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_image = keras.preprocessing.image.load_img('Prediction/4.jpg',target_size=(64,64))\n",
        "test_image = keras.preprocessing.image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image,axis=0)\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53f559d1",
      "metadata": {
        "id": "53f559d1",
        "outputId": "2a53f322-8ac1-41d1-9c36-73a0765b38f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tulip\n"
          ]
        }
      ],
      "source": [
        "if result[0][0]==1:\n",
        "    print('Daisy')\n",
        "elif result[0][1]==1:\n",
        "    print('Dandelion')\n",
        "elif result[0][2]==1:\n",
        "    print('Rose')\n",
        "elif result[0][3]==1:\n",
        "    print('SunFlower')\n",
        "elif result[0][4]==1:\n",
        "    print('Tulip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "298c101d",
      "metadata": {
        "id": "298c101d",
        "outputId": "ad8af32d-e274-478e-b84a-dc7d36ba1d5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e84fbc8",
      "metadata": {
        "id": "5e84fbc8"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "flowerrecognitionsystem.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}